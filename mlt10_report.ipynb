{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classification of Depression and Gender by Vocal Characteristics\n",
    "In this project, we will train a Random Forest Classifier to determine whether a participant has depression based on speech data from a clinical interview. The dataset contains 107 participants, 63 of which are male and 44 of which are female. Of these participants, 30 have depression (17 female, 14 male). By varying the weights and features included in the model training, we will demonstrate how differing analysis techniques can have significant impact on the model's classification performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** MATH OPERATIONS ****\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# **** DATA MANIPULATION ****\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general functions\n",
    "color_dict = {\n",
    "    'all features': 'mediumpurple',\n",
    "    'top performing features (depression)': 'darkviolet',\n",
    "    'top perfoming features (gender)': 'plum',\n",
    "    're-weighted features': 'indigo'\n",
    "}\n",
    "def load_features(path, labels_df):\n",
    "    dataframes = []\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        if file.split('.')[1] != 'csv':\n",
    "            continue\n",
    "        df = pd.read_csv(os.path.join(path, file), header=None)\n",
    "        participant_id = int(file.split(\"_\")[1].split(\".\")[0]) # Get ID from file name\n",
    "        df[\"Participant_ID\"] = participant_id\n",
    "        dataframes.append(df)\n",
    "        \n",
    "    # Combine into a single dataframe\n",
    "    data_df = pd.concat(dataframes)\n",
    "    return data_df.merge(labels_df, on=\"Participant_ID\")\n",
    "\n",
    "def analyze_results(test_df, display_results=True, pred_label='Depression'):\n",
    "    # Group by participant and average predictions \n",
    "    participant_predictions = test_df.groupby(\"Participant_ID\")[\"predictions\"].mean()\n",
    "\n",
    "    # Binarize the predictions from 0.5 threshold\n",
    "    threshold = 0.05\n",
    "    participant_predictions_binarized = (participant_predictions >= threshold).astype(int)\n",
    "\n",
    "    # Join aggregated predictions back with the depression labels\n",
    "    participant_labels = test_df.groupby(\"Participant_ID\")[pred_label].first()\n",
    "\n",
    "    # Filter data by gender\n",
    "    male_participants = test_df[test_df[\"Gender\"] == 1][\"Participant_ID\"].unique()\n",
    "    female_participants = test_df[test_df[\"Gender\"] == 0][\"Participant_ID\"].unique()\n",
    "\n",
    "    # Calculate accuracies for all, male, and female participants\n",
    "    all_metrics_depression = calculate_accuracy(participant_labels, \n",
    "                                                participant_predictions_binarized, \"All participants\",\n",
    "                                                display_results=display_results)\n",
    "    if display_results:\n",
    "        print(\"\")\n",
    "    male_metrics = calculate_accuracy(participant_labels.loc[male_participants],\n",
    "                                       participant_predictions_binarized.loc[male_participants], \"Male participants\",\n",
    "                                       display_results=display_results)\n",
    "    if display_results:\n",
    "        print(\"\")\n",
    "    female_metrics = calculate_accuracy(participant_labels.loc[female_participants], \n",
    "                                        participant_predictions_binarized.loc[female_participants],\n",
    "                                          \"Female participants\", display_results=display_results)\n",
    "\n",
    "    # Calculate EO\n",
    "    eo = (1 - abs(male_metrics[\"tpr\"] - female_metrics[\"tpr\"]))\n",
    "    if display_results:\n",
    "        print(f\"Equality of Opportunity (EO): {eo:.2f}\")\n",
    "\n",
    "    return all_metrics_depression, male_metrics, female_metrics, eo\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred, group, display_results=True):\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate Balanced Accuracy\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Extract TP, FP, TN, FN\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    tpr = tp / (tp + fn) # True Positive Rate\n",
    "    tnr = tn / (tn + fp) # True Negative Rate\n",
    "    fpr = fp / (fp + tn) # False Positive Rate\n",
    "    fnr = fn / (fn + tp) # False Negative Rate\n",
    "    \n",
    "    # Store metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"balanced_accuracy\": balanced_accuracy,\n",
    "        \"tpr\": tpr,\n",
    "        \"tnr\": tnr,\n",
    "        \"fpr\": fpr,\n",
    "        \"fnr\": fnr\n",
    "    }\n",
    "    if display_results:\n",
    "        print(f\"Metrics for {group}:\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"Balanced Accuracy: {balanced_accuracy:.2f}\")\n",
    "        print(f\"True Positive Rate (TPR): {tpr:.2f}\")\n",
    "        print(f\"True Negative Rate (TNR): {tnr:.2f}\")\n",
    "        print(f\"False Positive Rate (FPR): {fpr:.2f}\")\n",
    "        print(f\"False Negative Rate (FNR): {fnr:.2f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train_random_forest(df:pd.DataFrame, classification_feat:str):\n",
    "    # split into validation and train\n",
    "    train_df, validation_df = train_test_split(df, test_size=.3)\n",
    "    train_feat = train_df[classification_feat].values.tolist()\n",
    "    validation_feat = validation_df[classification_feat].values.tolist()\n",
    "    train_arr = train_df.drop(columns=[classification_feat]).to_numpy()\n",
    "    validation_arr = validation_df.drop(columns = [classification_feat]).to_numpy()\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "    # clf = RandomForestClassifier(num_trees, random_state=42, class_weight='balanced', max_depth=max_depth)\n",
    "    clf.fit(train_arr, train_feat)\n",
    "    pred = clf.predict(validation_arr)\n",
    "    acc = accuracy_score(validation_feat, pred)\n",
    "    # return model with best classification accuracy\n",
    "    return clf\n",
    "\n",
    "def bar_graph(vals:dict, measures:list, title:str):\n",
    "    x = np.arange(len(measures))  # the label locations\n",
    "    width = 0.2  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    for attribute, measurement in vals.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute, color=color_dict[attribute])\n",
    "        ax.bar_label(rects, padding=5)\n",
    "        multiplier += 1\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x + width, measures)\n",
    "    ax.legend(loc='upper left', ncols=4)\n",
    "    ax.set_ylim(0, 1)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in dataset & labels\n",
    "labels_df = pd.read_csv(\"labels.csv\")\n",
    "train_df = load_features(\"features_train\", labels_df)\n",
    "test_df = load_features(\"features_test\", labels_df)\n",
    "# append feature names\n",
    "features = pd.read_csv('feature_description.csv',\n",
    "                    encoding = 'ISO-8859-1', \n",
    "                    names=['feature', 'description'])['feature'].values.tolist()\n",
    "col_names = {x:features[x] for x in range(88)}\n",
    "train_df.rename(columns=col_names, inplace=True)\n",
    "test_df.rename(columns=col_names, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem (1a) Classification of Gender and Depression\n",
    "TODO Fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem (a.i) Depression Classification\n",
    "TODO Fill in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have these values at the end \n",
    "all_metrics_depression = 0\n",
    "male_metrics_depression = 0\n",
    "female_metrics_depression = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem (a.ii) Gender Classification\n",
    "TODO fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have these values at the end\n",
    "all_metrics_gender = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem (1b) Depression Feature Selection\n",
    "In this section, we will repeat the same depression classification as above on only the features with the strongest correlation with depression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform depression classification on the data\n",
    "correlation_tups = []\n",
    "for col in train_df.columns:\n",
    "    if col in ['Participant_ID', 'Depression']:\n",
    "        continue\n",
    "    correlation_tups.append((col, train_df[col].corr(train_df['Depression'])))\n",
    "correlation_tups = sorted(correlation_tups, key=lambda x: abs(x[1]), reverse=True)\n",
    "top_twenty_feats = {correlation_tups[x][0]:round(correlation_tups[x][1], 3)  for x in range(20)}\n",
    "print('Top twenty features correlated with depression: \\n')\n",
    "for key, val in top_twenty_feats.items():\n",
    "    print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The participants with depression more frequently spoke loudly (loudness_sma3) and with more fluctuations (spectralFlux). There is also slight correlation between the vocal range (semitone) and the speaker's depression. Since the majority of participants with depression were female, there is a correlation between gender and depression, as well.\n",
    "\n",
    "We will now train a Random Forest Classifier to predict depression using only the features most strongly correlated with depression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model on filtered features\n",
    "class_acc_dep_fs, bca_dep_fs, male_class_acc_dep_fs, male_bca_dep_fs, female_class_acc_dep_fs, female_bca_dep_fs, eo_dep_fs = [],[],[],[],[], [], []\n",
    "for n in range(10, 51, 5):\n",
    "    # select top performing features\n",
    "    features = [correlation_tups[x][0] for x in range(n)] + ['Depression']\n",
    "    filtered_df = train_df.loc[:, features]\n",
    "    # build random forest on these features\n",
    "    best_rand_forest = train_random_forest(filtered_df, 'Depression')\n",
    "    filtered_test = test_df.loc[:, features]\n",
    "    predictions = best_rand_forest.predict(filtered_test.drop(columns=['Depression']).to_numpy())\n",
    "    # store accuracies\n",
    "    test_df_pred = test_df.copy()\n",
    "    test_df_pred['predictions'] = predictions\n",
    "    x = test_df_pred.columns.values.tolist()\n",
    "    all_res, male_res, female_res, eo_res = analyze_results(test_df_pred, display_results=False)\n",
    "    class_acc_dep_fs.append(all_res['accuracy'])\n",
    "    bca_dep_fs.append(all_res['balanced_accuracy'])\n",
    "    male_class_acc_dep_fs.append(male_res['accuracy'])\n",
    "    male_bca_dep_fs.append(male_res['balanced_accuracy'])\n",
    "    female_class_acc_dep_fs.append(female_res['accuracy'])\n",
    "    female_bca_dep_fs.append(female_res['balanced_accuracy'])\n",
    "    eo_dep_fs.append(eo_res)\n",
    "\n",
    "\n",
    "# plot results\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "num_feats = range(10, 51, 5)\n",
    "ax.plot(num_feats, class_acc_dep_fs, label = \"Classification Accuracy\", color='darkviolet') \n",
    "ax.plot(num_feats, male_class_acc_dep_fs, label = \"Male Classification Accuracy\", color='royalblue') \n",
    "ax.plot(num_feats, female_class_acc_dep_fs, label = \"Female Classification Accuracy\", color='violet') \n",
    "ax.plot(num_feats, bca_dep_fs, label = \"Balanced Classification Accuracy\", color='darkviolet', linestyle='dashed') \n",
    "ax.plot(num_feats, male_bca_dep_fs, label = \"Male Balanced Classification Accuracy\", color='royalblue', linestyle='dashed') \n",
    "ax.plot(num_feats, female_bca_dep_fs, label = \"Female Balanced Classification Accuracy\", color='violet', linestyle='dashed') \n",
    "ax.plot(num_feats, eo_dep_fs, label = \"Equality of Opportunity\", color='darkviolet', linestyle='dotted')\n",
    "ax.set_title('Depression Classification Metrics Over Feature Selection')\n",
    "ax.set_xlabel('Number of Features Analyzed')\n",
    "ax.set_ylabel('Classification Accuracy')\n",
    "fig.tight_layout()\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.15, 0.5, 0.5, 0.5)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows the depression classification accuracy measures over male and female participants as the number of features included in the model increase. With minimal (10) features included in the model training, the Random Forest Classifier performs much better on female participants than on male participants. As more features (with decreasing correlation) increase, the classification accuracy on male participants increases, while the classification accuracy on female participants decreases. As the number of features increase, the equality of opportunity nears 60% and the overall classification and balanced classification accuracy nears 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ind = bca_dep_fs.index(max(bca_dep_fs))\n",
    "best_male_ind = male_bca_dep_fs.index(max(male_bca_dep_fs))\n",
    "best_female_ind = female_bca_dep_fs.index(max(female_bca_dep_fs))\n",
    "measures = ['Acc', 'BCA', 'Male Acc', 'Male BCA', 'Female Acc', 'Female BCA', 'EO']\n",
    "all_metrics_depression = {x:round(y, 2) for x,y in all_metrics_depression.items()}\n",
    "male_metrics = {x:round(y, 2) for x,y in male_metrics_depression.items()}\n",
    "female_metrics = {x:round(y, 2) for x,y in female_metrics_depression.items()}\n",
    "class_acc = [round(x, 2) for x in class_acc_dep_fs]\n",
    "male_class_acc = [round(x, 2) for x in male_class_acc_dep_fs]\n",
    "female_class_acc = [round(x, 2) for x in female_class_acc_dep_fs]\n",
    "bca = [round(x, 2) for x in bca_dep_fs]\n",
    "male_bca = [round(x, 2) for x in male_bca_dep_fs]\n",
    "female_bca = [round(x, 2) for x in female_bca_dep_fs]\n",
    "vals = {\n",
    "    'all features': [all_metrics_depression['accuracy'], all_metrics_depression['balanced_accuracy'], \n",
    "                     male_metrics['accuracy'], male_metrics['balanced_accuracy'], \n",
    "                     female_metrics['accuracy'], female_metrics['balanced_accuracy'], .6],\n",
    "    'top performing features (depression)': [class_acc[best_ind], bca[best_ind], \n",
    "                          male_class_acc[best_male_ind], male_bca[best_male_ind],\n",
    "                          female_class_acc[best_female_ind], female_bca[best_female_ind], eo_dep_fs[best_ind]],     \n",
    "}\n",
    "bar_graph(vals, measures, 'Depression Classification Metrics With Varied Feature Selection Methods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The balanced classification accuracy sees little change from the best performing feature-selection model to the original model. The overall classification accuracy is significantly higher with the original model than with the feature selection model, but these values would likely converge as the number of features included in the analysis increases. \n",
    "The original model performs better on classifying the male participants, with a 9% difference in the balanced classificaiton accuracy. However, the feature-selection model performs better on classifying female participants, with a 10% increase in the balanced classification accuracy. Furthermore, the Equality of Opportunity score increases 20% with the feature-selection model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem (1c) Gender Feature Selection\n",
    "TODO Fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in\n",
    "\n",
    "# line graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem (1d) Mitigating Bias Via Removing Gender-Dependent Features\n",
    "TODO Fill in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in\n",
    "\n",
    "# bar graph comparing to part a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem (1e) Mitigating Bias Via Other Approaches\n",
    "\n",
    "TODO Fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in\n",
    "\n",
    "# bar graph comparing to part a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
